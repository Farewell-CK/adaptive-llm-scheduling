import time
import asyncio
import logging
import httpx
import os
from enum import Enum
from collections import deque
from fastapi import FastAPI, Request
from fastapi.responses import StreamingResponse, JSONResponse

# ================= é…ç½®ä¸é˜ˆå€¼ (Theory Parameters) =================

# 1. å®è§‚æ§åˆ¶å‚æ•° (Q-HAP)
HAP_HIGH_WATERMARK = 10   # é•¿é˜Ÿåˆ—ç§¯å‹è¶…è¿‡ 10 ä¸ªï¼Œå‡†å¤‡æ‰©å®¹
HAP_LOW_WATERMARK = 2     # é•¿é˜Ÿåˆ—ç§¯å‹ä½äº 2 ä¸ªï¼Œå‡†å¤‡ç¼©å®¹
HAP_COOLDOWN = 5          # çŠ¶æ€åˆ‡æ¢å†·å´æ—¶é—´ (ç§’)ï¼Œé˜²æ­¢æŠ–åŠ¨

# 2. å¾®è§‚æ§åˆ¶å‚æ•° (RASP)
RASP_STEAL_COOLDOWN = 2.0 # çŸ­èŠ‚ç‚¹å¿…é¡»ç©ºé—²è¶…è¿‡ 2ç§’ æ‰èƒ½è¢«çªƒå–

# 3. é™æ€å®šä¹‰ (æ ¹æ®ä½ çš„ 4 ä¸ª Unit)
WORKER_URLS = [
    "http://localhost:8001/v1/chat/completions", # Unit 1
    "http://localhost:8002/v1/chat/completions", # Unit 2
    "http://localhost:8003/v1/chat/completions", # Unit 3
    "http://localhost:8004/v1/chat/completions"  # Unit 4
]
STATIC_THRESHOLD = 3000   # åŒºåˆ†é•¿çŸ­ä»»åŠ¡çš„ Token é˜ˆå€¼

# ==============================================================

logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s", datefmt="%H:%M:%S")
logger = logging.getLogger("AdaSplit")

app = FastAPI()
# ç¦ç”¨ç¯å¢ƒä»£ç†å˜é‡ï¼ˆä¾‹å¦‚ socks5 ä»£ç†å¯¼è‡´éœ€è¦ socksioï¼‰ï¼Œæœ¬è·¯ç”±åªè½¬å‘åˆ°æœ¬æœº workerã€‚
http_client = httpx.AsyncClient(
    timeout=None,
    limits=httpx.Limits(max_keepalive_connections=20, max_connections=20),
    trust_env=False,
)

class TaskType(Enum):
    LONG = "LONG"
    SHORT = "SHORT"

# --- 1. Worker æŠ½è±¡ (çŠ¶æ€ç®¡ç†çš„æœ€å°å•å…ƒ) ---
class Worker:
    def __init__(self, worker_id, url):
        self.id = worker_id
        self.url = url
        self.current_role = TaskType.LONG # é»˜è®¤ä¸º Longï¼Œä¼šè¢« Scheduler ä¿®æ”¹
        self.is_busy = False
        self.last_active_time = time.time() # ç”¨äº RASP è®¡ç®—ç©ºé—²æ—¶é•¿

    def mark_busy(self):
        self.is_busy = True
    
    def mark_idle(self):
        self.is_busy = False
        self.last_active_time = time.time()

    def get_idle_duration(self):
        if self.is_busy:
            return 0
        return time.time() - self.last_active_time

    def __repr__(self):
        return f"[W{self.id}:{self.current_role.value[0]}]"

# --- 2. æ ¸å¿ƒè°ƒåº¦å™¨ (The Brain) ---
class AdaSplitScheduler:
    def __init__(self):
        # åˆå§‹åŒ– 4 ä¸ª Worker
        self.workers = [Worker(i+1, url) for i, url in enumerate(WORKER_URLS)]
        
        # åˆå§‹çŠ¶æ€ï¼šBalanced (2 Long : 2 Short)
        # å¼ºåˆ¶è®¾å®š: 0,1 ä¸º Long; 2,3 ä¸º Short
        self.workers[0].current_role = TaskType.LONG
        self.workers[1].current_role = TaskType.LONG
        self.workers[2].current_role = TaskType.SHORT
        self.workers[3].current_role = TaskType.SHORT

        # ç­‰å¾…é˜Ÿåˆ— (å­˜æ”¾ Router æš‚æ—¶å¤„ç†ä¸è¿‡æ¥çš„è¯·æ±‚)
        # å­˜å‚¨æ ¼å¼: (TaskType, asyncio.Future, request_body)
        self.queue_long = deque()
        self.queue_short = deque()
        
        # çŠ¶æ€æ§åˆ¶
        self.last_rebalance_time = time.time()

    def get_partition_status(self):
        """è¿”å›å½“å‰çš„åˆ†ç»„çŠ¶æ€ (e.g., 3:1)"""
        n_long = sum(1 for w in self.workers if w.current_role == TaskType.LONG)
        n_short = sum(1 for w in self.workers if w.current_role == TaskType.SHORT)
        return n_long, n_short

    # === Part A: Q-HAP å®è§‚è°ƒåº¦é€»è¾‘ (Background Loop) ===
    async def run_qhap_loop(self):
        logger.info("å¯åŠ¨ Q-HAP å®è§‚è°ƒåº¦ç›‘æ§...")
        while True:
            await asyncio.sleep(1) # 1ç§’è¿è¡Œä¸€æ¬¡
            
            now = time.time()
            if now - self.last_rebalance_time < HAP_COOLDOWN:
                continue

            q_long_size = len(self.queue_long)
            n_long, n_short = self.get_partition_status()
            
            # --- æ‰©å®¹é€»è¾‘ (Scale Up) ---
            # å¦‚æœé•¿é˜Ÿåˆ—ç§¯å‹ä¸¥é‡ï¼Œä¸” Short ç»„è¿˜æœ‰å¯Œä½™ (è‡³å°‘ä¿ç•™1ä¸ª)
            if q_long_size > HAP_HIGH_WATERMARK and n_short > 1:
                # æ‰¾ä¸€ä¸ª Short Worker å˜æˆ Long
                target = next((w for w in self.workers if w.current_role == TaskType.SHORT), None)
                if target:
                    target.current_role = TaskType.LONG
                    self.last_rebalance_time = now
                    logger.warning(f"ğŸŒŠ [Q-HAP Trigger] æ‰©å®¹! é•¿ç§¯å‹={q_long_size}. åˆ‡æ¢ Worker {target.id} -> LONG. (å½“å‰ {n_long+1}:{n_short-1})")

            # --- ç¼©å®¹é€»è¾‘ (Scale Down) ---
            # å¦‚æœé•¿é˜Ÿåˆ—å¾ˆç©ºï¼Œä¸”æˆ‘ä»¬æœ‰å¤šä½™çš„ Long Worker (æ¢å¤ Balanced 2:2)
            # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬è®¾å®š Default æ˜¯ 2:2ï¼Œæ‰€ä»¥åªæœ‰ n_long > 2 æ—¶æ‰ç¼©å®¹
            elif q_long_size < HAP_LOW_WATERMARK and n_long > 2:
                # æ‰¾ä¸€ä¸ª Long Worker å˜æˆ Short (ä¼˜å…ˆæ‰¾ç¼–å·å¤§çš„)
                target = next((w for w in reversed(self.workers) if w.current_role == TaskType.LONG), None)
                if target:
                    target.current_role = TaskType.SHORT
                    self.last_rebalance_time = now
                    logger.info(f"ğŸƒ [Q-HAP Trigger] ç¼©å®¹. é•¿ç§¯å‹={q_long_size}. åˆ‡æ¢ Worker {target.id} -> SHORT. (å½“å‰ {n_long-1}:{n_short+1})")

    # === Part B: RASP å¾®è§‚åˆ†å‘é€»è¾‘ (Per Request) ===
    def try_get_worker(self, task_type: TaskType):
        """
        å°è¯•è·å–ä¸€ä¸ªå¯ç”¨ Workerã€‚
        åŒ…å«ï¼šæœ¬èŒå·¥ä½œåˆ†é… + RASP çªƒå–é€»è¾‘
        """
        
        # 1. ä¼˜å…ˆæ‰¾ã€æœ¬èŒå·¥ä½œã€‘ä¸”ç©ºé—²çš„ Worker
        # ------------------------------------------------
        candidates = [w for w in self.workers if w.current_role == task_type and not w.is_busy]
        if candidates:
            return candidates[0] # è¿”å›ç¬¬ä¸€ä¸ªç©ºé—²çš„æœ¬èŒ Worker

        # 2. RASP çªƒå–é€»è¾‘ (Risk-Aware Stealing Policy)
        # ------------------------------------------------
        # åªæœ‰ Long ä»»åŠ¡å…è®¸å»å· Short èŠ‚ç‚¹ (æ¿€è¿›ç­–ç•¥)
        # Short ä»»åŠ¡ä¸å…è®¸å· Long (å› ä¸ºé•¿ä»»åŠ¡å¤ªæ…¢ï¼Œä¸ä»…ä¸èµšåè€Œäº)
        if task_type == TaskType.LONG:
            # ç­›é€‰å¯ä»¥è¢«å·çš„ Short Worker
            # æ¡ä»¶å…¬å¼: Role=SHORT AND Queue_Short=Empty AND Idle_Time > Threshold
            
            short_q_empty = (len(self.queue_short) == 0)
            
            for w in self.workers:
                if w.current_role == TaskType.SHORT and not w.is_busy:
                    # RASP æ ¸å¿ƒå…¬å¼æ£€æŸ¥
                    if short_q_empty and w.get_idle_duration() > RASP_STEAL_COOLDOWN:
                        logger.info(f"ğŸ¥· [RASP Steal] Worker {w.id} (Short) æ­£åœ¨è¢«çªƒå–æ‰§è¡Œ Long ä»»åŠ¡! (Idle: {w.get_idle_duration():.1f}s)")
                        return w
        
        return None # æ²¡æœ‰å¯ç”¨èµ„æº

scheduler = AdaSplitScheduler()

# --- è¾…åŠ©å‡½æ•° ---
def estimate_token_count(messages):
    if not messages: return 0
    txt = "".join([str(m.get("content", "")) for m in messages])
    return len(txt) // 4

async def process_request(worker, body, request_obj):
    """å®é™…æ‰§è¡Œè½¬å‘ï¼Œç®¡ç† Worker å¿™/é—²çŠ¶æ€"""
    worker.mark_busy()
    try:
        # æ„é€ è¯·æ±‚
        req = http_client.build_request("POST", worker.url, json=body, timeout=None)
        r = await http_client.send(req, stream=True)
        return StreamingResponse(
            r.aiter_raw(), 
            status_code=r.status_code, 
            media_type=r.headers.get("content-type"),
            background=None
        )
    finally:
        # æ— è®ºæˆåŠŸå¤±è´¥ï¼Œè¯·æ±‚ç»“æŸåæ ‡è®°ä¸ºç©ºé—²
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ç®€å•å¤„ç†ï¼ŒçœŸå®åœºæ™¯å¯èƒ½éœ€è¦å¤„ç† Stream ç»“æŸçš„å›è°ƒ
        # å¯¹äº vLLM Streamï¼Œè¿™é‡Œå…¶å®æ˜¯ header è¿”å›å°± mark_idle äº†ï¼Œè¿™åœ¨å¹¶å‘æ§åˆ¶ä¸Šæ˜¯ä¸ç²¾ç¡®çš„
        # ä½†å¯¹äºè®ºæ–‡å®éªŒï¼Œä¸ºäº†åˆ¶é€ æ’é˜Ÿï¼Œæˆ‘ä»¬å¯ä»¥åœ¨è¿™é‡ŒåŠ ä¸€ä¸ªç®€å•çš„ await r.read() æˆ–è€…
        # æ›´å¥½çš„æ–¹å¼æ˜¯å‡è®¾ Worker å¹¶å‘èƒ½åŠ›æ˜¯ 1 (Request Level)ï¼Œ
        # æˆ–è€…æˆ‘ä»¬ä»…æŠŠ Router å½“åš Dispatcherï¼ŒWorker å†…éƒ¨å…¶å®æ”¯æŒ Batchingã€‚
        # 
        # ã€é‡è¦ä¿®æ­£ã€‘ï¼švLLM æœ¬èº«æ”¯æŒå¹¶å‘ (Continuous Batching)ã€‚
        # æˆ‘ä»¬çš„ Worker.is_busy = True å®é™…ä¸Šæ˜¯æŠŠ Worker å½“æˆäº† "Slot"ã€‚
        # ä¸ºäº†è®©å®éªŒæ•ˆæœæ˜æ˜¾ï¼Œæˆ‘ä»¬è¿™é‡Œã€ä¸ã€‘åº”è¯¥ä¸€å‘è¯·æ±‚å°±é‡Šæ”¾ Workerï¼Œ
        # è€Œæ˜¯åº”è¯¥è®© Router è®¤ä¸º Worker æ»¡è½½äº†ã€‚
        # ä½†ç”±äºæˆ‘ä»¬æ²¡æ³•çŸ¥é“ Stream ä»€ä¹ˆæ—¶å€™ç»“æŸï¼Œç®€åŒ–èµ·è§ï¼š
        # æˆ‘ä»¬è¿™é‡Œä¸åšä¸¥æ ¼çš„ Worker é”å®šï¼Œè€Œæ˜¯åªåšç®€å•çš„è®¡æ•°ï¼Œæˆ–è€…
        # æˆ‘ä»¬çš„ç®—æ³•å‡è®¾æ˜¯ Request-Level çš„è°ƒåº¦ã€‚
        
        # ä¸ºäº†è®©å®éªŒæ’é˜Ÿæ•ˆæœæœ€æ˜æ˜¾ (Hol Blocking)ï¼Œæˆ‘ä»¬æš‚æ—¶è®¾ä¸ºï¼š
        # å‘é€è¯·æ±‚ -> åªè¦å»ºç«‹äº†è¿æ¥ -> å°±è®¤ä¸º Worker ç©ºé—²äº† (æŠŠå‹åŠ›ç»™ vLLM å†…éƒ¨é˜Ÿåˆ—)
        # æˆ–è€…ï¼Œä¸ºäº†æ¨¡æ‹Ÿ Router ç«¯çš„æ’é˜Ÿï¼Œæˆ‘ä»¬å¯ä»¥åœ¨è¿™é‡Œç­‰å¾…ã€‚
        
        # *å¯¹äºæœ¬å®éªŒ*ï¼šæˆ‘ä»¬ä¸ç­‰å¾… Stream ç»“æŸï¼Œå› ä¸ºé‚£éœ€è¦è§£æ SSEã€‚
        # æˆ‘ä»¬åªè´Ÿè´£åˆ†å‘ã€‚Load Balancing ç”± vLLM å†…éƒ¨å¤„ç†ä¸€éƒ¨åˆ†ï¼Œ
        # ä½† Worker é€‰æ‹©ç”±æˆ‘ä»¬å†³å®šã€‚
        
        worker.mark_idle() 
        # é‡æ–°è§¦å‘ä¸€æ¬¡è°ƒåº¦ï¼Œçœ‹é˜Ÿåˆ—é‡Œæœ‰æ²¡æœ‰ç­‰å¾…çš„
        asyncio.create_task(dispatch_queue())

async def dispatch_queue():
    """æ¶ˆè´¹ç­‰å¾…é˜Ÿåˆ—ä¸­çš„ä»»åŠ¡"""
    # 1. å¤„ç† Short é˜Ÿåˆ— (é«˜ä¼˜)
    while scheduler.queue_short:
        worker = scheduler.try_get_worker(TaskType.SHORT)
        if worker:
            task_future, body, req_obj = scheduler.queue_short.popleft()
            # å¯åŠ¨ä»»åŠ¡
            asyncio.create_task(run_task(worker, body, req_obj, task_future))
        else:
            break # æ²¡èµ„æºäº†

    # 2. å¤„ç† Long é˜Ÿåˆ—
    while scheduler.queue_long:
        worker = scheduler.try_get_worker(TaskType.LONG)
        if worker:
            task_future, body, req_obj = scheduler.queue_long.popleft()
            asyncio.create_task(run_task(worker, body, req_obj, task_future))
        else:
            break

async def run_task(worker, body, req_obj, future):
    try:
        response = await process_request(worker, body, req_obj)
        future.set_result(response)
    except Exception as e:
        future.set_exception(e)

# --- FastAPI æ¥å£ ---

@app.on_event("startup")
async def startup():
    asyncio.create_task(scheduler.run_qhap_loop())

@app.post("/v1/chat/completions")
async def chat_completions(request: Request):
    body = await request.json()
    token_len = estimate_token_count(body.get("messages", []))
    
    # 1. åˆ†ç±»
    task_type = TaskType.LONG if token_len > STATIC_THRESHOLD else TaskType.SHORT
    
    # 2. å°è¯•ç›´æ¥è·å– Worker
    worker = scheduler.try_get_worker(task_type)
    
    if worker:
        # log åªæœ‰åœ¨ RASP æ²¡è§¦å‘æ—¶æ‰æ‰“ï¼Œä¸ç„¶ RASP é‚£é‡Œæ‰“è¿‡äº†
        # logger.info(f"Direct Dispatch {task_type.value} -> Worker {worker.id}")
        return await process_request(worker, body, request)
    
    else:
        # 3. æ²¡èµ„æºï¼Œè¿›å…¥é˜Ÿåˆ— (Queuing)
        # è¿™æ˜¯ä¸€ä¸ªç®€å•çš„â€œæŒ‚èµ·â€é€»è¾‘
        loop = asyncio.get_running_loop()
        future = loop.create_future()
        
        if task_type == TaskType.LONG:
            scheduler.queue_long.append((future, body, request))
            if len(scheduler.queue_long) % 5 == 0:
                logger.info(f"ğŸ“¥ Long Task Queued. Size: {len(scheduler.queue_long)}")
        else:
            scheduler.queue_short.append((future, body, request))
        
        # ç­‰å¾…è°ƒåº¦å™¨å¤„ç† Future
        return await future

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=5000)
