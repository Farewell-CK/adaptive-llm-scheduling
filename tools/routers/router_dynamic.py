import time
import asyncio
import logging
import httpx
import os
from enum import Enum
from collections import deque
from fastapi import FastAPI, Request
from fastapi.responses import StreamingResponse, JSONResponse

# ================= é…ç½®ä¸é˜ˆå€¼ (Theory Parameters) =================

# 1. å®è§‚æ§åˆ¶å‚æ•° (Q-HAP)
HAP_HIGH_WATERMARK = 10   # é•¿é˜Ÿåˆ—ç§¯å‹è¶…è¿‡ 10 ä¸ªï¼Œå‡†å¤‡æ‰©å®¹
HAP_LOW_WATERMARK = 2     # é•¿é˜Ÿåˆ—ç§¯å‹ä½äº 2 ä¸ªï¼Œå‡†å¤‡ç¼©å®¹
HAP_COOLDOWN = 5          # çŠ¶æ€åˆ‡æ¢å†·å´æ—¶é—´ (ç§’)ï¼Œé˜²æ­¢æŠ–åŠ¨

# 2. å¾®è§‚æ§åˆ¶å‚æ•° (RASP)
RASP_STEAL_COOLDOWN = 2.0 # çŸ­èŠ‚ç‚¹å¿…é¡»ç©ºé—²è¶…è¿‡ 2ç§’ æ‰èƒ½è¢«çªƒå–
WORKER_CONCURRENCY_LIMIT = 8 # æ¯ä¸ª Worker (vLLM Instance) å…è®¸çš„æœ€å¤§å¹¶å‘è¯·æ±‚æ•°

# 3. é™æ€å®šä¹‰ (æ ¹æ®ä½ çš„ 4 ä¸ª Unit)
WORKER_URLS = [
    "http://localhost:8001/v1/chat/completions", # Unit 1
    "http://localhost:8002/v1/chat/completions", # Unit 2
    "http://localhost:8003/v1/chat/completions", # Unit 3
    "http://localhost:8004/v1/chat/completions"  # Unit 4
]
STATIC_THRESHOLD = 3000   # åŒºåˆ†é•¿çŸ­ä»»åŠ¡çš„ Token é˜ˆå€¼

# ==============================================================

logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s", datefmt="%H:%M:%S")
logger = logging.getLogger("AdaSplit")

app = FastAPI()
# ç¦ç”¨ç¯å¢ƒä»£ç†å˜é‡ï¼ˆä¾‹å¦‚ socks5 ä»£ç†å¯¼è‡´éœ€è¦ socksioï¼‰ï¼Œæœ¬è·¯ç”±åªè½¬å‘åˆ°æœ¬æœº workerã€‚
http_client = httpx.AsyncClient(
    timeout=None,
    limits=httpx.Limits(max_keepalive_connections=100, max_connections=200),
    trust_env=False,
)

class TaskType(Enum):
    LONG = "LONG"
    SHORT = "SHORT"

# --- 1. Worker æŠ½è±¡ (çŠ¶æ€ç®¡ç†çš„æœ€å°å•å…ƒ) ---
class Worker:
    def __init__(self, worker_id, url):
        self.id = worker_id
        self.url = url
        self.current_role = TaskType.LONG # é»˜è®¤ä¸º Longï¼Œä¼šè¢« Scheduler ä¿®æ”¹
        self.active_requests = 0
        self.last_active_time = time.time() # ç”¨äº RASP è®¡ç®—ç©ºé—²æ—¶é•¿

    def inc_requests(self):
        self.active_requests += 1
    
    def dec_requests(self):
        self.active_requests = max(0, self.active_requests - 1)
        if self.active_requests == 0:
            self.last_active_time = time.time()

    def can_accept(self):
        return self.active_requests < WORKER_CONCURRENCY_LIMIT

    def get_idle_duration(self):
        if self.active_requests > 0:
            return 0
        return time.time() - self.last_active_time

    def __repr__(self):
        return f"[W{self.id}:{self.current_role.value[0]}:{self.active_requests}]"

# --- 2. æ ¸å¿ƒè°ƒåº¦å™¨ (The Brain) ---
class AdaSplitScheduler:
    def __init__(self):
        # åˆå§‹åŒ– 4 ä¸ª Worker
        self.workers = [Worker(i+1, url) for i, url in enumerate(WORKER_URLS)]
        
        # åˆå§‹çŠ¶æ€ï¼šBalanced (2 Long : 2 Short)
        # å¼ºåˆ¶è®¾å®š: 0,1 ä¸º Long; 2,3 ä¸º Short
        self.workers[0].current_role = TaskType.LONG
        self.workers[1].current_role = TaskType.LONG
        self.workers[2].current_role = TaskType.SHORT
        self.workers[3].current_role = TaskType.SHORT

        # ç­‰å¾…é˜Ÿåˆ— (å­˜æ”¾ Router æš‚æ—¶å¤„ç†ä¸è¿‡æ¥çš„è¯·æ±‚)
        # å­˜å‚¨æ ¼å¼: (TaskType, asyncio.Future, request_body)
        self.queue_long = deque()
        self.queue_short = deque()
        
        # çŠ¶æ€æ§åˆ¶
        self.last_rebalance_time = time.time()

    def get_partition_status(self):
        """è¿”å›å½“å‰çš„åˆ†ç»„çŠ¶æ€ (e.g., 3:1)"""
        n_long = sum(1 for w in self.workers if w.current_role == TaskType.LONG)
        n_short = sum(1 for w in self.workers if w.current_role == TaskType.SHORT)
        return n_long, n_short

    # === Part A: Q-HAP å®è§‚è°ƒåº¦é€»è¾‘ (Background Loop) ===
    async def run_qhap_loop(self):
        logger.info("å¯åŠ¨ Q-HAP å®è§‚è°ƒåº¦ç›‘æ§...")
        while True:
            await asyncio.sleep(1) # 1ç§’è¿è¡Œä¸€æ¬¡
            
            now = time.time()
            if now - self.last_rebalance_time < HAP_COOLDOWN:
                continue

            q_long_size = len(self.queue_long)
            n_long, n_short = self.get_partition_status()
            
            # --- æ‰©å®¹é€»è¾‘ (Scale Up) ---
            # å¦‚æœé•¿é˜Ÿåˆ—ç§¯å‹ä¸¥é‡ï¼Œä¸” Short ç»„è¿˜æœ‰å¯Œä½™ (è‡³å°‘ä¿ç•™1ä¸ª)
            if q_long_size > HAP_HIGH_WATERMARK and n_short > 1:
                # æ‰¾ä¸€ä¸ª Short Worker å˜æˆ Long
                target = next((w for w in self.workers if w.current_role == TaskType.SHORT), None)
                if target:
                    target.current_role = TaskType.LONG
                    self.last_rebalance_time = now
                    logger.warning(f"ğŸŒŠ [Q-HAP Trigger] æ‰©å®¹! é•¿ç§¯å‹={q_long_size}. åˆ‡æ¢ Worker {target.id} -> LONG. (å½“å‰ {n_long+1}:{n_short-1})")

            # --- ç¼©å®¹é€»è¾‘ (Scale Down) ---
            # å¦‚æœé•¿é˜Ÿåˆ—å¾ˆç©ºï¼Œä¸”æˆ‘ä»¬æœ‰å¤šä½™çš„ Long Worker (æ¢å¤ Balanced 2:2)
            # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬è®¾å®š Default æ˜¯ 2:2ï¼Œæ‰€ä»¥åªæœ‰ n_long > 2 æ—¶æ‰ç¼©å®¹
            elif q_long_size < HAP_LOW_WATERMARK and n_long > 2:
                # æ‰¾ä¸€ä¸ª Long Worker å˜æˆ Short (ä¼˜å…ˆæ‰¾ç¼–å·å¤§çš„)
                target = next((w for w in reversed(self.workers) if w.current_role == TaskType.LONG), None)
                if target:
                    target.current_role = TaskType.SHORT
                    self.last_rebalance_time = now
                    logger.info(f"ğŸƒ [Q-HAP Trigger] ç¼©å®¹. é•¿ç§¯å‹={q_long_size}. åˆ‡æ¢ Worker {target.id} -> SHORT. (å½“å‰ {n_long-1}:{n_short+1})")

    # === Part B: RASP å¾®è§‚åˆ†å‘é€»è¾‘ (Per Request) ===
    def try_get_worker(self, task_type: TaskType):
        """
        å°è¯•è·å–ä¸€ä¸ªå¯ç”¨ Workerã€‚
        åŒ…å«ï¼šæœ¬èŒå·¥ä½œåˆ†é… + RASP çªƒå–é€»è¾‘
        """
        
        # 1. ä¼˜å…ˆæ‰¾ã€æœ¬èŒå·¥ä½œã€‘ä¸”è¿˜æœ‰å¹¶å‘ä½™é‡çš„ Worker
        # ------------------------------------------------
        candidates = [w for w in self.workers if w.current_role == task_type and w.can_accept()]
        if candidates:
            # è´Ÿè½½å‡è¡¡ï¼šé€‰æ‹©å½“å‰è´Ÿè½½æœ€ä½çš„é‚£ä¸ª
            return min(candidates, key=lambda x: x.active_requests)

        # 2. RASP çªƒå–é€»è¾‘ (Risk-Aware Stealing Policy)
        # ------------------------------------------------
        # åªæœ‰ Long ä»»åŠ¡å…è®¸å»å· Short èŠ‚ç‚¹ (æ¿€è¿›ç­–ç•¥)
        if task_type == TaskType.LONG:
            # ç­›é€‰å¯ä»¥è¢«å·çš„ Short Worker
            short_q_empty = (len(self.queue_short) == 0)
            
            for w in self.workers:
                if w.current_role == TaskType.SHORT and w.can_accept():
                    # RASP æ ¸å¿ƒå…¬å¼æ£€æŸ¥ï¼šçŸ­ä»»åŠ¡é˜Ÿåˆ—ä¸ºç©ºï¼Œä¸”èŠ‚ç‚¹å·²ç©ºé—²ä¸€æ®µæ—¶é—´
                    if short_q_empty and w.get_idle_duration() > RASP_STEAL_COOLDOWN:
                        logger.info(f"ğŸ¥· [RASP Steal] Worker {w.id} (Short) æ­£åœ¨è¢«çªƒå–æ‰§è¡Œ Long ä»»åŠ¡! (Load: {w.active_requests})")
                        return w
        
        return None # æ²¡æœ‰å¯ç”¨èµ„æº

scheduler = AdaSplitScheduler()

# --- è¾…åŠ©å‡½æ•° ---
def estimate_token_count(messages):
    if not messages: return 0
    txt = "".join([str(m.get("content", "")) for m in messages])
    return len(txt) // 4

async def process_request(worker, body, request_obj):
    """å®é™…æ‰§è¡Œè½¬å‘ï¼Œç®¡ç† Worker å¿™/é—²çŠ¶æ€"""
    worker.inc_requests()
    try:
        # æ„é€ è¯·æ±‚
        req = http_client.build_request("POST", worker.url, json=body, timeout=None)
        r = await http_client.send(req, stream=True)
        return StreamingResponse(
            r.aiter_raw(), 
            status_code=r.status_code, 
            media_type=r.headers.get("content-type"),
            background=None
        )
    finally:
        # åªè¦è¯·æ±‚å“åº”å¼€å§‹è¿”å›ï¼ˆå¦‚æœæ˜¯ Streamingï¼Œè¿™ä¸ä»£è¡¨ç»“æŸï¼Œä½†åœ¨æœ¬ Router æ¶æ„ä¸­
        # ä¸ºäº†ä¸é˜»å¡åç»­è¯·æ±‚è¿›å…¥ vLLM å†…éƒ¨é˜Ÿåˆ—ï¼Œæˆ‘ä»¬åœ¨å‘é€åä¸ä¹…æˆ–ç»“æŸåé‡Šæ”¾ã€‚
        # å®é™…ä¸Š vLLM å†…éƒ¨æœ‰æ›´å¤§çš„é˜Ÿåˆ—ã€‚
        # ä¸ºäº†æ›´å‡†ç¡®æ¨¡æ‹Ÿå¹¶å‘æ§åˆ¶ï¼Œç†æƒ³æƒ…å†µåº”è¯¥åœ¨ Streaming ç»“æŸæ—¶ dec_requestsã€‚
        
        # TODO: å¦‚æœè¦ä¸¥æ ¼é™åˆ¶ vLLM å†…éƒ¨å¹¶å‘ï¼Œéœ€è¦è§£æ SSE å¹¶åœ¨ç»“æŸæ—¶å›è°ƒã€‚
        # ç›®å‰è¿™é‡Œçš„é€»è¾‘æ˜¯ï¼šè¯·æ±‚å‘å‡ºå¹¶å»ºç«‹æµè¿æ¥åå³è§†ä¸ºå ç”¨ä¸€ä¸ª slotã€‚
        # ç”±äº FastAPI StreamingResponse çš„ç‰¹æ€§ï¼Œæˆ‘ä»¬æ— æ³•ç®€å•åœ°åœ¨æ­¤å¤„ await ç»“æŸã€‚
        
        worker.dec_requests() 
        # é‡æ–°è§¦å‘ä¸€æ¬¡è°ƒåº¦ï¼Œçœ‹é˜Ÿåˆ—é‡Œæœ‰æ²¡æœ‰ç­‰å¾…çš„
        asyncio.create_task(dispatch_queue())

async def dispatch_queue():
    """æ¶ˆè´¹ç­‰å¾…é˜Ÿåˆ—ä¸­çš„ä»»åŠ¡"""
    # 1. å¤„ç† Short é˜Ÿåˆ— (é«˜ä¼˜)
    while scheduler.queue_short:
        worker = scheduler.try_get_worker(TaskType.SHORT)
        if worker:
            task_future, body, req_obj = scheduler.queue_short.popleft()
            # å¯åŠ¨ä»»åŠ¡
            asyncio.create_task(run_task(worker, body, req_obj, task_future))
        else:
            break # æ²¡èµ„æºäº†

    # 2. å¤„ç† Long é˜Ÿåˆ—
    while scheduler.queue_long:
        worker = scheduler.try_get_worker(TaskType.LONG)
        if worker:
            task_future, body, req_obj = scheduler.queue_long.popleft()
            asyncio.create_task(run_task(worker, body, req_obj, task_future))
        else:
            break

async def run_task(worker, body, req_obj, future):
    try:
        response = await process_request(worker, body, req_obj)
        future.set_result(response)
    except Exception as e:
        future.set_exception(e)

# --- FastAPI æ¥å£ ---

@app.on_event("startup")
async def startup():
    asyncio.create_task(scheduler.run_qhap_loop())

@app.post("/v1/chat/completions")
async def chat_completions(request: Request):
    body = await request.json()
    token_len = estimate_token_count(body.get("messages", []))
    
    # 1. åˆ†ç±»
    task_type = TaskType.LONG if token_len > STATIC_THRESHOLD else TaskType.SHORT
    
    # 2. å°è¯•ç›´æ¥è·å– Worker
    worker = scheduler.try_get_worker(task_type)
    
    if worker:
        # log åªæœ‰åœ¨ RASP æ²¡è§¦å‘æ—¶æ‰æ‰“ï¼Œä¸ç„¶ RASP é‚£é‡Œæ‰“è¿‡äº†
        # logger.info(f"Direct Dispatch {task_type.value} -> Worker {worker.id}")
        return await process_request(worker, body, request)
    
    else:
        # 3. æ²¡èµ„æºï¼Œè¿›å…¥é˜Ÿåˆ— (Queuing)
        # è¿™æ˜¯ä¸€ä¸ªç®€å•çš„â€œæŒ‚èµ·â€é€»è¾‘
        loop = asyncio.get_running_loop()
        future = loop.create_future()
        
        if task_type == TaskType.LONG:
            scheduler.queue_long.append((future, body, request))
            if len(scheduler.queue_long) % 5 == 0:
                logger.info(f"ğŸ“¥ Long Task Queued. Size: {len(scheduler.queue_long)}")
        else:
            scheduler.queue_short.append((future, body, request))
        
        # ç­‰å¾…è°ƒåº¦å™¨å¤„ç† Future
        return await future

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=5000)
